{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1-zfG5UGyPUHT6YE-rweUi6G0npQFbJDY",
      "authorship_tag": "ABX9TyOkdKI1+TBHcdT/CFuPz3uU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sukyeong02/24-1-AI/blob/main/11_1_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaIlMUa2HKYf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Flatten,Embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(3)\n",
        "tf.random.set_seed(3)\n",
        "\n",
        "train_data = pd.read_csv(\"/content/drive/MyDrive/24-1학기 코딩 수업/인공지능/train_mydataset_6000.csv\", header=0, names=['title','label'])\n",
        "X_train = train_data['title']\n",
        "Y_train = train_data['label']\n",
        "test_data = pd.read_csv(\"/content/drive/MyDrive/24-1학기 코딩 수업/인공지능/test_mydataset_1500.csv\", header=0)\n",
        "X_test = test_data['title']\n",
        "Y_test = test_data['label']\n",
        "\n",
        "print(\"첫 번째 입력: \", X_train[0])\n",
        "Y_train_onehot = to_categorical(Y_train)\n",
        "Y_test_onehot = to_categorical(Y_test)\n",
        "print(\"첫 번째 one-hot출력:\", Y_train_onehot[0])\n",
        "\n",
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "from numpy import array\n",
        "\n",
        "token = Tokenizer()\n",
        "token.fit_on_texts(X_train)\n",
        "# print(token.word_index)\n",
        "x = token.texts_to_sequences(X_train)\n",
        "x1 = token.texts_to_sequences(X_test)\n",
        "print(\"첫 번째 토큰화 결과:\", x[0])\n",
        "\n",
        "padded_X_train = pad_sequences(x, 14)\n",
        "padded_X_test = pad_sequences(x1, 14)\n",
        "\n",
        "max_train = 0\n",
        "max_test = 0\n",
        "\n",
        "for i in x:\n",
        "  if len(i) > max_train:\n",
        "    max_train = len(i)\n",
        "\n",
        "for i in x1:\n",
        "  if len(i) > max_test:\n",
        "    max_test = len(i)\n",
        "\n",
        "print(\"학습셋 제목 최대 길이: \", max_train)\n",
        "print(\"테스트셋 제목 최대 길이: \", max_test)\n",
        "print(\"첫 번째 패딩 토큰: \", padded_X_train[0])\n",
        "\n",
        "word_size = len(token.word_index) +1\n",
        "print(\"Word Size: \", word_size)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(word_size, 8, input_length=14))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(padded_X_train, Y_train_onehot, epochs=20)\n",
        "print(\"Accuracy: %.4f\" % (model.evaluate(padded_X_test, Y_test_onehot)[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eIaQ2DiIpYA",
        "outputId": "1dd8dfe0-52b1-4185-d161-2772b096649b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "첫 번째 입력:  버거킹 바삭한 신메뉴 3000원도 안되는 가격\n",
            "첫 번째 one-hot출력: [0. 1. 0.]\n",
            "첫 번째 토큰화 결과: [1, 2804, 41, 5168, 1512, 23]\n",
            "학습셋 제목 최대 길이:  14\n",
            "테스트셋 제목 최대 길이:  11\n",
            "첫 번째 패딩 토큰:  [   0    0    0    0    0    0    0    0    1 2804   41 5168 1512   23]\n",
            "Word Size:  12464\n",
            "Epoch 1/20\n",
            "188/188 [==============================] - 7s 33ms/step - loss: 0.9122 - accuracy: 0.6413\n",
            "Epoch 2/20\n",
            "188/188 [==============================] - 2s 9ms/step - loss: 0.6655 - accuracy: 0.7235\n",
            "Epoch 3/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.4287 - accuracy: 0.8337\n",
            "Epoch 4/20\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.2509 - accuracy: 0.9377\n",
            "Epoch 5/20\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.1470 - accuracy: 0.9747\n",
            "Epoch 6/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0907 - accuracy: 0.9903\n",
            "Epoch 7/20\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0596 - accuracy: 0.9945\n",
            "Epoch 8/20\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0410 - accuracy: 0.9973\n",
            "Epoch 9/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0295 - accuracy: 0.9985\n",
            "Epoch 10/20\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0220 - accuracy: 0.9990\n",
            "Epoch 11/20\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0169 - accuracy: 0.9997\n",
            "Epoch 12/20\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0132 - accuracy: 0.9997\n",
            "Epoch 13/20\n",
            "188/188 [==============================] - 1s 6ms/step - loss: 0.0106 - accuracy: 0.9998\n",
            "Epoch 14/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "188/188 [==============================] - 1s 5ms/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "188/188 [==============================] - 1s 4ms/step - loss: 0.0042 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "188/188 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 1.0000\n",
            "47/47 [==============================] - 0s 2ms/step - loss: 0.4135 - accuracy: 0.8673\n",
            "Accuracy: 0.8673\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RPk_3EFEFAym"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}